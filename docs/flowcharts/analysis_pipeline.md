# Analysis Pipeline Flowchart

This document contains a detailed flowchart, ASCII diagram, and node-to-code mapping for `src/Analysis/analysis_pipline.py`.

---

## Mermaid Flowchart

```mermaid
flowchart TB
  Start([Start: call full_multi_peak_analysis(x,y, fit_kwargs?, detection_kwargs...)])
  Detect[Call find_all_peak_initial_params(x, y, **detection_kwargs)]
  NoPeaks{initial_params_list empty?}
  ReturnNoPeaks[/Return {'error':'No significant peaks were found.'}/]
  PrepareFit[Prepare fit kwargs and call fit_engine(x, y, initial_params_list, **fit_kwargs)]
  FitTry{fit_engine raises RuntimeError or ValueError?}
  ReturnFitError[/Return {'error': f'Fitting failed...'} /]
  FitSuccess[/popt, pcov returned/]
  ComputeUncert[Try perr = sqrt(diag(pcov)); on error perr = nan array]
  ComputeFit[Compute y_fit = multi_peak_model(x, *popt)]
  ComputeChi[Compute chi_squared = sum((y - y_fit)**2 / var); var = where(y>0,y,1)]
  ComputeDoF[Compute dof = len(x) - len(popt); reduced_chi2 = chi_squared/dof or nan]
  FormatBG[Extract background params: bkg_opt and bkg_err (popt[0:3], perr[0:3])]
  FormatPeaks[Loop: for i in range(N_peaks) build peak_results list]
  ReturnReport[/Return structured dict with refined_params, initial_params, goodness_of_fit/]
  End([End])

  Start --> Detect
  Detect --> NoPeaks
  NoPeaks -- yes --> ReturnNoPeaks --> End
  NoPeaks -- no --> PrepareFit
  PrepareFit --> FitTry
  FitTry -- raises --> ReturnFitError --> End
  FitTry -- ok --> FitSuccess --> ComputeUncert --> ComputeFit --> ComputeChi --> ComputeDoF --> FormatBG --> FormatPeaks --> ReturnReport --> End
```

---

## ASCII Flowchart

```
Start: full_multi_peak_analysis(x, y, fit_kwargs=None, **detection_kwargs)
 |
 v
Call find_all_peak_initial_params(x, y, **detection_kwargs)
 |
 +-- If empty --> Return {"error": "No significant peaks were found."}
 |
 v
Prepare fit_kwargs (if None set to {}) and call fit_engine(x, y, initial_params_list, **fit_kwargs)
 |
 +-- If fit_engine raises RuntimeError or ValueError -> Return {"error": "Fitting failed to converge or input error: {e}"}
 |
 v
Receive popt, pcov
 |
 v
Try perr = sqrt(diag(pcov))
 |-- if diag fails -> perr = array of NaNs
 |
 v
Compute y_fit = multi_peak_model(x, *popt)
 |
 v
Compute sigma_y_sq = where(y > 0, y, 1)
 |
 v
chi_squared = sum((y - y_fit)**2 / sigma_y_sq)
 |
 v
n_params = len(popt)
dof = len(x) - n_params
reduced_chi_squared = chi_squared / dof  (or nan if dof<=0)
 |
 v
Construct bkg_opt = {'c0': popt[0], 'c1': popt[1], 'c2': popt[2]}
bkg_err = {'c0': perr[0], 'c1': perr[1], 'c2': perr[2]}
 |
 v
N_peaks = (len(popt)-3)//3
for i in 0..N_peaks-1:
    start_idx = 3 + i*3
    append {'A': popt[start_idx], 'A_err': perr[start_idx], 'mu': popt[start_idx+1], ...}
 |
 v
Return {
  'refined_params': {'Background': {...}, 'Peaks': [...]},
  'initial_params': initial_params_list,
  'goodness_of_fit': {'chi_squared': ..., 'reduced_chi_squared': ..., 'dof': ...}
}
```

---

## Node-to-code mapping and notes

- Start: `full_multi_peak_analysis(x, y, fit_kwargs=None, **detection_kwargs)`
  - Code: `def full_multi_peak_analysis(...)` in `src/Analysis/analysis_pipline.py`.

- Detection
  - Code: `initial_params_list = find_all_peak_initial_params(x, y, **detection_kwargs)`
  - Note: returns list of `(mu0, A0, sigma0)` tuples.

- Fit preparation & call
  - Code: `popt, pcov = fit_engine(x, y, initial_params_list, **fit_kwargs)`
  - `fit_engine` builds initial guesses `p0`, `bounds`, calls `scipy.optimize.curve_fit`.
  - Configurable in updated code: `mu_window_factor`, `c2_upper`, `verbose` via `fit_kwargs`.

- Fit error handling
  - Code: caught in `except (RuntimeError, ValueError) as e` and returned as `{'error': ...}`.

- On successful fit
  - `popt`, `pcov` from `curve_fit`.

- Uncertainty extraction
  - Code: `perr = np.sqrt(np.diag(pcov))` with fallback to NaNs if `pcov` invalid.

- Model evaluation
  - Code: `y_fit = multi_peak_model(x, *popt)`

- Chi-squared and DoF
  - Code:
    - `sigma_y_sq = np.where(y > 0, y, 1)`
    - `chi_squared = np.sum((y - y_fit)**2 / sigma_y_sq)`
    - `dof = len(x) - len(popt)`
    - `reduced_chi_squared = chi_squared / dof if dof > 0 else np.nan`

- Formatting results
  - Background: `popt[0:3]` and `perr[0:3]`
  - Peaks: loop `N_peaks = (len(popt) - 3)//3` and extract per-peak triplets

---

## How to view

- Open this file in VS Code. If you have the "Markdown Preview Mermaid Support" extension (or built-in Mermaid support), you can view the Mermaid chart directly in preview.
- Alternatively, copy the Mermaid code block into an online Mermaid live editor to render.

---

## Next steps (optional)

- I can add an SVG/PNG of the flowchart to `docs/flowcharts/`.
- I can add unit tests referencing the pipeline's main branches.

---

*Generated by the analysis assistant.*
